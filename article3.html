<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<title>Lost in Data - Points de vigilance</title>
<link rel="stylesheet" type="text/css" href="main_style.css"/>
</head>
<body>
<header>
<nav>
<ul>
<li><a href="#">Accueil</a></li>
<li><a href="glossaire.html">Glossaire</a></li>
<li><a href="#">Qui sommes nous ?</a></li>
<li><a href="#">Contact</a></li>
</ul>
</nav>
</header>

<main>

<h1>Points de vigilance</h1>
<div>
<p>
Si l’apport du Big Data est irréfutable, et malgré l’enthousiasme croissant pour les technologies qui lui sont rattachées, il convient de leur définir des limites. Nos préoccupations économiques doivent être couplées avec une prise en compte des problèmes écologiques, techniques et éthiques soulevés par le Big Data. Sur cette page, nous proposons de traiter ces trois problèmes sous la forme de points de vigilance. Ces points ne doivent pas être négligés si vous décidez d’investir du temps et de l’argent dans le Big Data. Le but ici n’est pas de freiner les ambitions innovantes mais de fournir les clés argumentatives permettant de faire face aux critiques légitimes auxquelles vous allez faire face.
</p>
</div>
<div class="">
<h2>1. Big Data et environnement : quels enjeux ?</h2>
<div class="">
<p>
Pour faire face aux mesures préconisées par les organismes internationaux pour la protection de l’environnement, plusieurs entreprises, en France comme dans le reste du monde, sont en train de s’ouvrir à l’usage du Big Data afin d’optimiser leur efficacité énergétique.<br>
D’un point de vue environnemental, la mise en place de super calculateurs Big Data touche principalement trois aspects de l’activité en entreprise : l’optimisation des processus industriels, la gestion du management énergétique, la prévision de dysfonctionnements pour réduire les dépenses énergétiques inutiles.</p>
<p>
L’analyse de données massives peut permettre d’optimiser des processus industriels et donc de réduire les émissions polluantes associées. Si l’on prend l’exemple de la collecte de données dans une ferme, les fermiers peuvent recevoir en temps réel des informations sur leurs plantations, issues de capteurs et d’images satellites, afin de ne diffuser que la quantité d’eau nécessaire et la juste dose de pesticides. Grâce à ces flux de données (collectées et reformulées), l’automatisation du traitement des données permet aux fermiers d’avoir un suivi de leur travail et d’adapter leurs systèmes de gestion énergétique en fonction du besoin réel de leur plantation. Ceci entraîne à la fois une baisse des dépenses énergétiques inutiles et un impact environnemental de l’activité de l’entreprise réduit.</p>
<p>
Quel est le revers de la médaille ?</p>
<p>
Qui dit super calculateur, dit équipements terminaux, réseaux et centres de données. Tous ces éléments consommant à chaque étape de leur cycle de vie une puissance électrique importante qui produit du gaz à effet de serre.<br>
Sans trop s’attarder sur les évidentes dépenses énergétiques engendrées par la construction, le transport et l’élimination des équipements, il est intéressant de considérer quel est l’impact environnemental de l’usage des centres de données Big Data.</p>
<p>
En 2011, Google possédait à peu près 900 000 serveurs. Depuis, le million a été largement dépassé, et tous les géants du Web et de l’informatique suivent le mouvement. Avec l’explosion du cloud, la quantité de données stockées et, par conséquent, de centres de données va encore augmenter, tout comme leur consommation électrique.</p>
<p>
Selon une étude de Greenpeace, ces infrastructures engloutissent 1,5% de la consommation électrique à l’échelle mondiale, soit l’équivalent de la production de 30 centrales nucléaires.<br>
Ces chiffres sont destinés à montrer très rapidement si on considère à quelle vitesse le trafic internet mondial est en train d’augmenter au fil des ans (si en 1997 le trafic internet mondial augmentait de 100 Go/heure, en 2018 on estime une augmentation de 50 000 Go/seconde !), et cette croissance implique la mise en place de beaucoup de centres de données qui consomment de plus en plus d’énergie. Quel sera alors l’impact environnemental à l’échelle mondiale de ces infrastructures informatiques dans une dizaine d’années ?</p>
<p>
Il faut donc se demander si le passage à cette nouvelle technologie, avec ses gains dans un premier temps, ne produira pas des désavantages ultérieurs au fur et à mesure de son développement.
</p>
</div>


<h2>2. Une quantité de données incontrôlable ?</h2>
<div class="">
<p>
La plupart des entreprises croulent sous une quantité de données tellement importante qu'elles ne savent pas quoi en faire. Seulement 28 % des entreprises estiment que la collection de données apporte une valeur stratégique.</p>
<p>
La tendance des entreprises à collecter toujours plus de données se heurte à un problème majeur. Les données brutes étant trop nombreuses, la majorité d’entre-elles ne servira jamais.</p>
<p>
Une donnée est noyée dans un flot de données. Leur traitement nécessite des algorithmes très complexes.</p>
<p>
Face à l’immensité et à la variété, il est difficile d’identifier les données de qualité et il faut nettoyer régulièrement celles qui comportent des erreurs. Cela demande beaucoup de temps et d’argent. Ainsi, les professionnels de la business intelligence passent plus de la moitié de leur temps à nettoyer les données et à les préparer pour les intégrer dans les bases de données de l'entreprise.</p>
<p>
Des solutions existent pour remédier à ce problème. Certains pensent par exemple que l’intelligence artificielle pourra, à terme, contribuer au nettoyage des données.</p>
</div>


<h2>3. Vers une éthique de l’exploitation des données</h2>
<div class="">
<h3>Protection des données</h3>
<p>
À l’heure des réseaux sociaux et des objets connectés, l’anonymat et la protection des données personnelles sont très peu respectés.</p>
<p>
D’ailleurs, la plupart des données collectées par les entreprises sont récoltées grâce aux clients eux-mêmes. Ils font parfois une confiance aveugle aux entreprises et deviennent acteurs de leur perte d’anonymat et de la divulgation de leurs données personnelles.</p>
<p>
S’il peut sembler légitime d’accorder sa confiance aux entreprises ayant pignon sur rue, les clients ne sont jamais à l’abri d’actes malveillants. En mai 2016, Orange a subi un piratage et s’est fait voler les données personnelles de plus d’un million de clients. Cela démontre qu’une entreprise en pointe dans le domaine de la protection des données reste vulnérable aux attaques des pirates et que ses clients peuvent en être victime.
Par ailleurs, les bases récoltant les données de patients peuvent susciter l’intérêt de groupes malintentionnés. Dans ce contexte, le secret médical peut être menacé.</p>
<p>
L’Europe joue ici le rôle de garde fou. Elle impose aux entreprises de « sécuriser les données personnelles contre tout traitement non autorisé ou illégal, mais aussi contre la perte accidentelle, la destruction ou l’altération des données personnelles en mettant en œuvre les mesures de sécurité physique, technique et organisationnelle appropriées ». Elle préconise également quatre mesures afin de garantir le respect de la vie privée : transparence, contrôle, intégration de la vie privée lors du développement des algorithmes, et responsabilisation des acteurs du développement. Mais cette autorité n’est pour l’heure que très peu respectée.
</p>

<h3>Non-objectivité des données</h3>
<p>
L’enregistrement permanent de données sur notre vie privée permet aux algorithmes d’effectuer des tâches variées. Ils peuvent par exemple anticiper le futur succès d’un employé avant même son recrutement, c’est ce que l’on appelle l’analyse prédictive. De même, dans le domaine de l’assurance, il peut proposer des tarifs adaptés à la conduite d’un individu ou adapté à l’état de forme d’un individu.</p>
<p>
On pense souvent que les ordinateurs sont neutres, qu’ils ne donnent pas leur avis et qu’ils fournissent des informations fiables et objectives. C’est loin d’être le cas.<br>
Car, lors de la conception d’un algorithme, le développeur fait des choix. Il porte la responsabilité de la façon dont se comporte l’ordinateur. C’est une illusion de croire en la neutralité des ordinateurs. Un algorithme est écrit par des humains qui, par nature, ne peuvent être neutres. Le Big Data n’est donc pas objectif.</p>
<p>
Pour illustrer ce propos, citons un exemple. Aux Etats-Unis, le Big Data est parfois utilisé pour libérer certains suspects sur parole. Dans ce système, la couleur de la peau n’est pas prise en compte afin d’éviter toute discrimination. Cependant, l’algorithme enregistre et prend en compte le code postal de résidence du suspect et le profil criminel de ses voisins. Finalement, l’appartenance ethnique du suspect est souvent identifiée et ce système perpétue des discriminations antérieures, tout en se donnant l’apparence de la neutralité.</p>
<p>
En conclusion, il faut garder à l’esprit qu’un individu n’est pas une simple statistique. Le Big Data doit être considéré comme un objet technologique intéressant mais il ne doit pas s’affranchir des considérations écologiques et éthiques. Les données recueillies doivent servir à créer du lien entre les clients et les entreprises, dans le respect de l’être humain et de l’éthique professionnelle.
</p>
</div>
</div>

</main>
<footer></footer>
</body>
</html>